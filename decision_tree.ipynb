{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8508fff2-ebcc-4768-9e9f-8d6d1b03b899",
   "metadata": {},
   "source": [
    "### Decision Tree from Scratch for Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20b12105-ae03-4be8-aee3-8a76287f89ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb0ba477-72f6-42a3-9aac-e50219068713",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    \"\"\"\n",
    "    A Decision Tree classifier supporting:\n",
    "    - Continuous and categorical features\n",
    "    - Multiclass classification\n",
    "    - Missing value handling\n",
    "    - Post-pruning with validation data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    max_depth : int or None\n",
    "        Maximum depth of the tree. If None, tree expands until pure leaves or no gain.\n",
    "    \n",
    "    min_samples_split : int\n",
    "        Minimum number of samples required to split a node.\n",
    "    \n",
    "    Methods:\n",
    "    --------\n",
    "    fit(X, y, feature_names=None, X_val=None, y_val=None):\n",
    "        Train the decision tree classifier.\n",
    "    \n",
    "    predict(X):\n",
    "        Predict class labels for samples in X.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_depth=None, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "        self.feature_names = None\n",
    "        \n",
    "    def fit(self, X, y, feature_names=None, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        Build the decision tree from training data.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : list of list\n",
    "            Training samples, each sample is a list of feature values.\n",
    "        y : list\n",
    "            Target class labels.\n",
    "        feature_names : list of str, optional\n",
    "            List of feature names in order.\n",
    "        X_val, y_val : optional\n",
    "            Validation data for post-pruning.\n",
    "        \"\"\"\n",
    "        self.feature_names = feature_names\n",
    "        self.tree = self._build_tree(X, y, depth=0)\n",
    "        \n",
    "        if X_val is not None and y_val is not None:\n",
    "            self._prune(self.tree, X_val, y_val)\n",
    "    \n",
    "    def _gini(self, y):\n",
    "        \"\"\"Calculate Gini impurity for labels y\"\"\"\n",
    "        counts = Counter(y)\n",
    "        n = len(y)\n",
    "        impurity = 1 - sum((count / n) ** 2 for count in counts.values())\n",
    "        return impurity\n",
    "    \n",
    "    def _split_dataset(self, X, y, feature_index, threshold):\n",
    "        \"\"\"\n",
    "        Split dataset based on feature at feature_index and threshold.\n",
    "        \n",
    "        For continuous features: left <= threshold, right > threshold.\n",
    "        For categorical features: left == threshold, right != threshold.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        (X_left, y_left), (X_right, y_right)\n",
    "        \"\"\"\n",
    "        X_left, y_left, X_right, y_right = [], [], [], []\n",
    "        for xi, yi in zip(X, y):\n",
    "            val = xi[feature_index]\n",
    "            if val is None:  # Missing values handled by ignoring this sample in split calculation\n",
    "                continue\n",
    "            if isinstance(threshold, (int, float)):  # Continuous feature\n",
    "                if val <= threshold:\n",
    "                    X_left.append(xi)\n",
    "                    y_left.append(yi)\n",
    "                else:\n",
    "                    X_right.append(xi)\n",
    "                    y_right.append(yi)\n",
    "            else:  # Categorical feature\n",
    "                if val == threshold:\n",
    "                    X_left.append(xi)\n",
    "                    y_left.append(yi)\n",
    "                else:\n",
    "                    X_right.append(xi)\n",
    "                    y_right.append(yi)\n",
    "        return (X_left, y_left), (X_right, y_right)\n",
    "    \n",
    "    def _best_split(self, X, y):\n",
    "        \"\"\"\n",
    "        Find the best split for the current node by maximizing Gini gain.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        best_feature_index, best_threshold, best_gain, best_splits\n",
    "        \"\"\"\n",
    "        base_gini = self._gini(y) # Parent Impurity\n",
    "        best_gain = 0\n",
    "        best_feature, best_threshold = None, None\n",
    "        best_splits = None\n",
    "        \n",
    "        n_features = len(X[0])\n",
    "        \n",
    "        for feature_index in range(n_features):\n",
    "            # Get all possible values for this feature, ignoring None\n",
    "            values = [x[feature_index] for x in X if x[feature_index] is not None]\n",
    "            unique_values = set(values)\n",
    "            \n",
    "            # For continuous features: try midpoints between sorted unique values\n",
    "            if all(isinstance(v, (int, float)) for v in unique_values):\n",
    "                sorted_vals = sorted(unique_values)\n",
    "                thresholds = [(sorted_vals[i] + sorted_vals[i+1])/2 for i in range(len(sorted_vals)-1)]\n",
    "            else:\n",
    "                # Categorical: thresholds are unique values themselves\n",
    "                thresholds = unique_values\n",
    "            \n",
    "            for threshold in thresholds:\n",
    "                (X_left, y_left), (X_right, y_right) = self._split_dataset(X, y, feature_index, threshold)\n",
    "                \n",
    "                if len(y_left) == 0 or len(y_right) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Calculate weighted Gini impurity after split\n",
    "                n = len(y_left) + len(y_right)\n",
    "                gini_left = self._gini(y_left)\n",
    "                gini_right = self._gini(y_right)\n",
    "                weighted_gini = (len(y_left) / n) * gini_left + (len(y_right) / n) * gini_right\n",
    "                \n",
    "                gain = base_gini - weighted_gini\n",
    "                \n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature_index\n",
    "                    best_threshold = threshold\n",
    "                    best_splits = ((X_left, y_left), (X_right, y_right))\n",
    "        \n",
    "        return best_feature, best_threshold, best_gain, best_splits\n",
    "    \n",
    "    def _build_tree(self, X, y, depth):\n",
    "        \"\"\"\n",
    "        Recursively build the decision tree.\n",
    "        \"\"\"\n",
    "        num_samples = len(y)\n",
    "        num_labels = len(set(y))\n",
    "        \n",
    "        # Stopping criteria\n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or (num_labels == 1) or (num_samples < self.min_samples_split):\n",
    "            leaf_label = Counter(y).most_common(1)[0][0]\n",
    "            return {'type': 'leaf', 'class': leaf_label}\n",
    "        \n",
    "        feature_index, threshold, gain, splits = self._best_split(X, y)\n",
    "        \n",
    "        if gain == 0 or splits is None:\n",
    "            leaf_label = Counter(y).most_common(1)[0][0]\n",
    "            return {'type': 'leaf', 'class': leaf_label}\n",
    "        \n",
    "        (X_left, y_left), (X_right, y_right) = splits\n",
    "        \n",
    "        left_branch = self._build_tree(X_left, y_left, depth + 1)\n",
    "        right_branch = self._build_tree(X_right, y_right, depth + 1)\n",
    "        \n",
    "        return {\n",
    "            'type': 'node',\n",
    "            'feature_index': feature_index,\n",
    "            'feature_name': self.feature_names[feature_index] if self.feature_names else None,\n",
    "            'threshold': threshold,\n",
    "            'left': left_branch,\n",
    "            'right': right_branch\n",
    "        }\n",
    "    \n",
    "    def _predict_sample(self, node, sample):\n",
    "        \"\"\"\n",
    "        Predict class label for a single sample by traversing the tree.\n",
    "        Missing values handled by traversing both branches and majority voting.\n",
    "        \"\"\"\n",
    "        if node['type'] == 'leaf':\n",
    "            return node['class']\n",
    "        \n",
    "        val = sample[node['feature_index']]\n",
    "        threshold = node['threshold']\n",
    "        \n",
    "        if val is None:\n",
    "            # Missing feature value: traverse both branches and return majority vote\n",
    "            left_pred = self._predict_sample(node['left'], sample)\n",
    "            right_pred = self._predict_sample(node['right'], sample)\n",
    "            return Counter([left_pred, right_pred]).most_common(1)[0][0]\n",
    "        \n",
    "        if isinstance(threshold, (int, float)):\n",
    "            # Continuous feature split\n",
    "            if val <= threshold:\n",
    "                return self._predict_sample(node['left'], sample)\n",
    "            else:\n",
    "                return self._predict_sample(node['right'], sample)\n",
    "        else:\n",
    "            # Categorical feature split\n",
    "            if val == threshold:\n",
    "                return self._predict_sample(node['left'], sample)\n",
    "            else:\n",
    "                return self._predict_sample(node['right'], sample)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict class labels for multiple samples.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : list of list\n",
    "            Samples to predict.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        List of predicted class labels.\n",
    "        \"\"\"\n",
    "        return [self._predict_sample(self.tree, sample) for sample in X]\n",
    "    \n",
    "    def _prune(self, node, X_val, y_val):\n",
    "        \"\"\"\n",
    "        Post-pruning using reduced error pruning on validation set.\n",
    "        \"\"\"\n",
    "        if node['type'] == 'leaf':\n",
    "            return\n",
    "        \n",
    "        # Prune children first\n",
    "        self._prune(node['left'], X_val, y_val)\n",
    "        self._prune(node['right'], X_val, y_val)\n",
    "        \n",
    "        # If both children are leaves, try pruning this node\n",
    "        if node['left']['type'] == 'leaf' and node['right']['type'] == 'leaf':\n",
    "            # Current prediction error\n",
    "            y_pred = [self._predict_sample(node, x) for x in X_val]\n",
    "            error_before = sum(yp != yt for yp, yt in zip(y_pred, y_val))\n",
    "            \n",
    "            # Temporarily prune node into leaf with majority class\n",
    "            combined_labels = []\n",
    "            for x in X_val:\n",
    "                val = x[node['feature_index']]\n",
    "                if val is None:\n",
    "                    continue\n",
    "                if isinstance(node['threshold'], (int, float)):\n",
    "                    if val <= node['threshold']:\n",
    "                        combined_labels.append(y_val[X_val.index(x)])\n",
    "                    else:\n",
    "                        combined_labels.append(y_val[X_val.index(x)])\n",
    "                else:\n",
    "                    combined_labels.append(y_val[X_val.index(x)])\n",
    "            if combined_labels:\n",
    "                majority_class = Counter(combined_labels).most_common(1)[0][0]\n",
    "            else:\n",
    "                majority_class = Counter(y_val).most_common(1)[0][0]\n",
    "            \n",
    "            # Save original node\n",
    "            original_node = node.copy()\n",
    "            node.clear()\n",
    "            node.update({'type': 'leaf', 'class': majority_class})\n",
    "            \n",
    "            # Prediction error after pruning\n",
    "            y_pred_pruned = [self._predict_sample(node, x) for x in X_val]\n",
    "            error_after = sum(yp != yt for yp, yt in zip(y_pred_pruned, y_val))\n",
    "            \n",
    "            # Revert if pruning doesn't improve error\n",
    "            if error_after > error_before:\n",
    "                node.clear()\n",
    "                node.update(original_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f4ab925-d6f4-4fa2-bc98-d0f1696d14e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "\n",
    "data = pd.read_csv('../data\\mnist_train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23a6dc06-7d65-400a-8e4c-25214555de02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1x1',\n",
       " '1x2',\n",
       " '1x3',\n",
       " '1x4',\n",
       " '1x5',\n",
       " '1x6',\n",
       " '1x7',\n",
       " '1x8',\n",
       " '1x9',\n",
       " '1x10',\n",
       " '1x11',\n",
       " '1x12',\n",
       " '1x17',\n",
       " '1x18',\n",
       " '1x19',\n",
       " '1x20',\n",
       " '1x21',\n",
       " '1x22',\n",
       " '1x23',\n",
       " '1x24',\n",
       " '1x25',\n",
       " '1x26',\n",
       " '1x27',\n",
       " '1x28',\n",
       " '2x1',\n",
       " '2x2',\n",
       " '2x3',\n",
       " '2x4',\n",
       " '2x25',\n",
       " '2x26',\n",
       " '2x27',\n",
       " '2x28',\n",
       " '3x1',\n",
       " '3x2',\n",
       " '3x27',\n",
       " '3x28',\n",
       " '4x1',\n",
       " '4x2',\n",
       " '4x28',\n",
       " '5x1',\n",
       " '6x1',\n",
       " '6x2',\n",
       " '7x1',\n",
       " '18x1',\n",
       " '21x1',\n",
       " '24x1',\n",
       " '24x2',\n",
       " '24x28',\n",
       " '25x1',\n",
       " '25x2',\n",
       " '25x28',\n",
       " '26x1',\n",
       " '26x2',\n",
       " '26x28',\n",
       " '27x1',\n",
       " '27x2',\n",
       " '27x3',\n",
       " '27x27',\n",
       " '27x28',\n",
       " '28x1',\n",
       " '28x2',\n",
       " '28x3',\n",
       " '28x4',\n",
       " '28x25',\n",
       " '28x26',\n",
       " '28x27',\n",
       " '28x28']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# constant features\n",
    "\n",
    "constant_features = [i for i in data.columns if data[i].nunique() == 1]\n",
    "constant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85ac3bed-3e1e-4c3c-b3d9-134e5420c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop constant Features\n",
    "\n",
    "data.drop(constant_features, axis= 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ad34153-098d-4c0f-9315-7caf4a0f6490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 718)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.iloc[:500,:]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43a81548-a353-4ed1-a429-1317d88692c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 717), (100, 717))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('label', axis= 1),\n",
    "                                                   data['label'],\n",
    "                                                   test_size= 0.2,\n",
    "                                                   random_state= 0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20982d52-462c-4f87-a3da-fe80156d8eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DecisionTreeClassifier at 0x1c4829a5f40>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create instsnce\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth= 5)\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88252c32-f624-4465-a297-d37d2bbe8311",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.tolist()\n",
    "y_train = y_train.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f193d6ad-e1e8-4281-9705-5b22e7e19587",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06375d27-5a42-472b-a89d-164fb900a526",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 9,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions\n",
    "\n",
    "tree.predict(X_test.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "241a27bc-148a-4905-9071-124ef43a6f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'node',\n",
       " 'feature_index': 523,\n",
       " 'feature_name': None,\n",
       " 'threshold': 61.0,\n",
       " 'left': {'type': 'node',\n",
       "  'feature_index': 359,\n",
       "  'feature_name': None,\n",
       "  'threshold': 3.0,\n",
       "  'left': {'type': 'leaf', 'class': 1},\n",
       "  'right': {'type': 'leaf', 'class': 4}},\n",
       " 'right': {'type': 'node',\n",
       "  'feature_index': 316,\n",
       "  'feature_name': None,\n",
       "  'threshold': 3.0,\n",
       "  'left': {'type': 'leaf', 'class': 2},\n",
       "  'right': {'type': 'leaf', 'class': 0}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view tree\n",
    "\n",
    "tree._build_tree(X_train, y_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "287b3fc0-5a5b-466d-9cc6-6eb8585f0f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: ['Yes']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'leaf', 'class': 'Yes'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample data\n",
    "data = pd.DataFrame({\n",
    "    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rainy', 'Rainy', 'Rainy', 'Overcast', 'Sunny'],\n",
    "    'Humidity': ['High', 'High', None, 'High', 'Normal', 'Normal', 'Normal', 'Normal'],\n",
    "    'Temperature': [85, 80, 83, 70, 68, 65, 64, 72],\n",
    "    'Windy': ['False', 'True', 'False', 'False', 'False', 'True', 'True', 'False'],\n",
    "    'Play': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'Yes']\n",
    "})\n",
    "\n",
    "X = data.drop(columns='Play')\n",
    "y = data['Play']\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=3)\n",
    "tree.fit(X.values.tolist(), y.tolist(), feature_names=X.columns.tolist())\n",
    "\n",
    "sample = ['Rainy', 'Normal', 70, 'False']\n",
    "print(\"Prediction:\", tree.predict([sample]))\n",
    "tree._build_tree(X,y,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
